{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports and Environment Setup","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\n# Suppress TensorFlow warnings\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\n# GPU configuration for better performance\nphysical_devices = tf.config.list_physical_devices(\"GPU\")\nif physical_devices:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    print(\"GPU is available and configured\")\nelse:\n    print(\"Using CPU for training\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  Data Loading and Preprocessing","metadata":{}},{"cell_type":"code","source":"# Load MNIST dataset\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\nprint(f\"Training data shape: {x_train.shape}, Labels shape: {y_train.shape}\")\nprint(f\"Test data shape: {x_test.shape}, Labels shape: {y_test.shape}\")\n\n# Data preprocessing\n# Reshape to include channel dimension and normalize\nx_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\nx_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n\n# Convert labels to categorical one-hot encoding\ny_train_cat = keras.utils.to_categorical(y_train, 10)\ny_test_cat = keras.utils.to_categorical(y_test, 10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data visualization","metadata":{}},{"cell_type":"code","source":"# Visualize some training examples\nplt.figure(figsize=(10, 5))\nfor i in range(10):\n    plt.subplot(2, 5, i+1)\n    plt.imshow(x_train[i].reshape(28, 28), cmap='gray')\n    plt.title(f\"Label: {y_train[i]}\")\n    plt.axis('off')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  Data Augmentation Setup","metadata":{}},{"cell_type":"code","source":"# Data augmentation for training robustness\ndata_augmentation = keras.Sequential([\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n    layers.RandomTranslation(0.1, 0.1)\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Definition","metadata":{}},{"cell_type":"code","source":"# Define a CNN model with increasing complexity\ndef create_cnn_model():\n    model = keras.Sequential([\n        # Input layer\n        keras.Input(shape=(28, 28, 1)),\n        \n        # Optional data augmentation (only applied during training)\n        data_augmentation,\n        \n        # First convolutional block\n        layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(pool_size=2),\n        layers.Dropout(0.25),\n        \n        # Second convolutional block\n        layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(pool_size=2),\n        layers.Dropout(0.25),\n        \n        # Third convolutional block\n        layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Dropout(0.25),\n        \n        # Flatten and dense layers\n        layers.Flatten(),\n        layers.Dense(256, activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Dropout(0.5),\n        layers.Dense(10, activation=\"softmax\")\n    ])\n    \n    return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  Model Compilation","metadata":{}},{"cell_type":"code","source":"# Create and compile the model\nmodel = create_cnn_model()\nmodel.compile(\n    loss=\"categorical_crossentropy\",\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    metrics=[\"accuracy\"]\n)\n\n# Model summary\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Callbacks for Training Optimization","metadata":{}},{"cell_type":"code","source":"# Learning rate scheduler for adaptive learning\ndef lr_scheduler(epoch, lr):\n    if epoch % 5 == 0 and epoch > 0:\n        return lr * 0.9\n    return lr\n\nlr_callback = keras.callbacks.LearningRateScheduler(lr_scheduler)\nearly_stopping = keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=5, restore_best_weights=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    x_train, y_train_cat,\n    batch_size=64,\n    epochs=20,\n    validation_split=0.1,\n    callbacks=[lr_callback, early_stopping],\n    verbose=1\n)\n\n# Evaluate the model\ntest_loss, test_acc = model.evaluate(x_test, y_test_cat, verbose=0)\nprint(f\"Test accuracy: {test_acc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Visualization","metadata":{}},{"cell_type":"code","source":"# Plot training history\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Evaluation with Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# Generate predictions\ny_pred = model.predict(x_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred_classes)\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n            xticklabels=range(10), yticklabels=range(10))\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred_classes))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prediction Visualization","metadata":{}},{"cell_type":"code","source":"# Visualize some predictions\ndef plot_predictions(x, y_true, y_pred, n=10):\n    plt.figure(figsize=(15, 4))\n    for i in range(n):\n        plt.subplot(1, n, i+1)\n        plt.imshow(x[i].reshape(28, 28), cmap='gray')\n        predicted = np.argmax(y_pred[i])\n        color = 'green' if predicted == y_true[i] else 'red'\n        plt.title(f\"True: {y_true[i]}\\nPred: {predicted}\", color=color)\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n# Show some correct and incorrect predictions\nplot_predictions(x_test[:10], y_test[:10], y_pred[:10])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Error Analysis","metadata":{}},{"cell_type":"code","source":"# Find and display some misclassified examples\nmisclassified_indices = np.where(y_pred_classes != y_test)[0]\nprint(f\"Number of misclassified examples: {len(misclassified_indices)}\")\n\nif len(misclassified_indices) > 0:\n    # Display some misclassified examples\n    n_display = min(10, len(misclassified_indices))\n    selected_indices = misclassified_indices[:n_display]\n    plot_predictions(\n        x_test[selected_indices], \n        y_test[selected_indices], \n        y_pred[selected_indices],\n        n=n_display\n    )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}