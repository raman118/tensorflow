{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# mean absolute error a detailed guid","metadata":{}},{"cell_type":"markdown","source":" How Does MAE Work?\nMAE calculates the absolute difference between predicted and actual values for each data point.\nIt then averages these absolute differences to compute the final error value.\nSince absolute values are used, MAE treats all errors equally, regardless of their direction (positive or negative).\n","metadata":{}},{"cell_type":"markdown","source":" When to Use MAE\n✅ When Outliers Are Expected: Since MAE isn’t drastically affected by large errors, it’s a great choice if your data has potential outliers.\n✅ When Interpretability Matters: Because MAE is in the same unit as the target variable, it’s easier for stakeholders to understand.\n✅ For Balanced Error Sensitivity: MAE treats all errors equally, making it suitable for scenarios where both small and large errors are equally important.","metadata":{}},{"cell_type":"markdown","source":"When Not to Use MAE\n❌ When Emphasizing Large Errors Is Important: Unlike MSE, MAE doesn’t punish larger errors more heavily. If you want to heavily penalize large deviations, MSE may be better.\n❌ In Gradient Descent (Rarely): Since MAE has a non-smooth derivative (its gradient is ±1), MSE often converges faster in gradient-based optimizers.\n❌ For Highly Noisy Data: MAE can become unstable if your dataset has extremely noisy features or fluctuating patterns.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import mean_absolute_error\n\n# Actual and predicted values\ny_true = np.array([100, 200, 300, 400])\ny_pred = np.array([110, 190, 320, 390])\n\n# Manual calculation\nmae_manual = np.mean(np.abs(y_true - y_pred))\nprint(\"Manual MAE calculation:\", mae_manual)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T19:15:04.199477Z","iopub.execute_input":"2025-03-17T19:15:04.199802Z","iopub.status.idle":"2025-03-17T19:15:04.811548Z","shell.execute_reply.started":"2025-03-17T19:15:04.199774Z","shell.execute_reply":"2025-03-17T19:15:04.810594Z"}},"outputs":[{"name":"stdout","text":"Manual MAE calculation: 12.5\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# using scikitlearn(recomended)\nmea_sklearn = mean_absolute_error(y_true , y_pred)\nprint(\"sklearn mae calculation:\" ,mea_sklearn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T19:17:39.668568Z","iopub.execute_input":"2025-03-17T19:17:39.668940Z","iopub.status.idle":"2025-03-17T19:17:39.674503Z","shell.execute_reply.started":"2025-03-17T19:17:39.668909Z","shell.execute_reply":"2025-03-17T19:17:39.673485Z"}},"outputs":[{"name":"stdout","text":"sklearn mae calculation: 12.5\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Key Takeaway\nMAE is best suited for regression tasks where outliers are expected, or when you need an easily interpretable error metric. However, it’s not ideal when large errors must be penalized more heavily.","metadata":{}},{"cell_type":"markdown","source":"# mean squared error (mse)","metadata":{}},{"cell_type":"markdown","source":"Mean Squared Error (MSE) is a widely used loss function for regression tasks. It measures the average of the squared differences between the actual values and the predicted values.","metadata":{}},{"cell_type":"markdown","source":"# How Does MSE Work?\n1. MSE calculates the squared difference between the predicted and actual values for each data point.\n\n2. It then averages these squared differences to compute the final error value.\n3. Since errors are squared, MSE heavily penalizes larger errors — making it more sensitive to outliers than MAE.","metadata":{}},{"cell_type":"markdown","source":"# key characters of mse\n1. ✅ Heavily Penalizes Large Errors: Because MSE squares the errors, larger deviations have a disproportionate impact on the final error.\n2. ✅ Continuous and Differentiable: The MSE loss function has a smooth gradient, making it ideal for gradient descent optimizers.\n3. ✅ Mathematical Simplicity: MSE's quadratic form is easy to compute and implement.\n\n","metadata":{}},{"cell_type":"markdown","source":"#  When to Use MSE\n1. ✅ When Large Errors Need Strong Penalization: MSE is ideal when you want your model to prioritize reducing large errors.\n2. ✅ In Models Using Gradient Descent: Since MSE has a smooth, continuous gradient (derivative), it behaves predictably in gradient-based optimizers like SGD or Adam.\n3. ✅ For Normally Distributed Errors: MSE assumes errors are normally distributed. If this is true, MSE will provide optimal results.","metadata":{}},{"cell_type":"markdown","source":"# When NOT to Use MSE\n1. ❌ When Outliers Are Present: MSE’s sensitivity to large errors can make your model unstable if your dataset contains outliers. In this case, MAE or Huber Loss may be better.\n2. ❌ When You Need Interpretable Results: Since MSE’s output is squared, the resulting error is no longer in the same unit as the original data, making it harder to explain.\n3. ❌ For Highly Imbalanced Datasets: MSE may focus too much on the larger values if the data distribution is skewed.","metadata":{}},{"cell_type":"markdown","source":"# code","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n# Actual and predicted values\ny_true = np.array([100, 200, 300, 400])\ny_pred = np.array([110, 190, 320, 390])\n\n# manual calculation\nmse_manuel = np.mean((y_pred-y_true)**2)\nprint(\"Manuel MSE calculation: \",mse_manuel)\n\n\n#using scikit-learn\nmse_sklearn = mean_squared_error(y_true , y_pred)\nprint(\"scikit mse calculations: \" , mse_sklearn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T19:29:23.181851Z","iopub.execute_input":"2025-03-17T19:29:23.182183Z","iopub.status.idle":"2025-03-17T19:29:23.187770Z","shell.execute_reply.started":"2025-03-17T19:29:23.182157Z","shell.execute_reply":"2025-03-17T19:29:23.186413Z"}},"outputs":[{"name":"stdout","text":"Manuel MSE calculation:  175.0\nscikit mse calculations:  175.0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# log loss","metadata":{}},{"cell_type":"markdown","source":"# what is logg loss \nLog Loss, also known as Logarithmic Loss, Binary Cross-Entropy, or Categorical Cross-Entropy, is a loss function used for classification tasks. It measures how far the predicted probabilities are from the actual labels.\n\nIn essence, Log Loss penalizes confident but wrong predictions more heavily than less confident wrong predictions. It’s the go-to loss function for probabilistic models like logistic regression and neural networks in classification tasks.","metadata":{}},{"cell_type":"markdown","source":"# How Does Log Loss Work?","metadata":{}},{"cell_type":"markdown","source":"Log Loss behaves like this:\n\nCorrect and Confident Prediction: If the model predicts 1 when the actual class is 1, or 0 when the actual class is 0, the Log Loss is low.\nWrong and Confident Prediction: If the model predicts 1 when the actual class is 0, or 0 when the actual class is 1, the Log Loss is very high.\nUncertain Predictions: Predictions close to 0.5 are treated as less confident, resulting in moderate penalties.","metadata":{}},{"cell_type":"markdown","source":"# when to use log loss\n✅ For Binary Classification Tasks: Log Loss is the default choice for models like logistic regression, support vector machines (SVM), and binary neural networks.\n✅ For Probabilistic Models: If your model outputs probabilities, Log Loss effectively measures the confidence of those predictions.\n✅ For Imbalanced Datasets: Log Loss performs well even with imbalanced datasets, as it directly evaluates prediction probabilities.","metadata":{}},{"cell_type":"markdown","source":"# when not to use log loss\n❌ When Predictions Are Not Probabilistic: Models that output hard labels (e.g., 0 or 1 directly) are unsuitable for Log Loss since it expects probability values.\n❌ When Outliers Are Severe: Like MSE, Log Loss heavily penalizes extreme misclassifications.\n❌ For Multi-Class Problems Without Modification: Use Categorical Cross-Entropy for multi-class classification.","metadata":{}},{"cell_type":"markdown","source":"# Visualizing Log Loss Behavior\nPrediction close to 1 for class 1: Low loss (good prediction)\nPrediction close to 0 for class 0: Low loss (good prediction)\nPrediction close to 0 for class 1: Very high loss (bad prediction)\nPrediction close to 1 for class 0: Very high loss (bad prediction)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import log_loss\n\n# Actual labels (binary classification)\ny_true = np.array([1, 0, 1, 0])\n\n# Predicted probabilities\ny_pred = np.array([0.9, 0.2, 0.1, 0.8])\n\n# Manual Calculation\nlog_loss_manual = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\nprint(\"Manual Log Loss Calculation:\", log_loss_manual)\n\n# Using Scikit-learn (recommended)\nlog_loss_sklearn = log_loss(y_true, y_pred)\nprint(\"Sklearn Log Loss Calculation:\", log_loss_sklearn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T21:29:02.785361Z","iopub.execute_input":"2025-03-17T21:29:02.785692Z","iopub.status.idle":"2025-03-17T21:29:03.504868Z","shell.execute_reply.started":"2025-03-17T21:29:02.785664Z","shell.execute_reply":"2025-03-17T21:29:03.503724Z"}},"outputs":[{"name":"stdout","text":"Manual Log Loss Calculation: 1.0601317681000455\nSklearn Log Loss Calculation: 1.0601317681000455\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"#  Log Loss for Multi-Class Classification","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import log_loss\n\n# Multi-class example\ny_true = [0, 2, 1, 2]  # Actual class labels\ny_pred = [\n    [0.9, 0.05, 0.05],\n    [0.1, 0.1, 0.8],\n    [0.3, 0.6, 0.1],\n    [0.05, 0.05, 0.9],\n]\n\nprint(\"Multi-class Log Loss:\", log_loss(y_true, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T21:29:51.375279Z","iopub.execute_input":"2025-03-17T21:29:51.375609Z","iopub.status.idle":"2025-03-17T21:29:51.383970Z","shell.execute_reply.started":"2025-03-17T21:29:51.375583Z","shell.execute_reply":"2025-03-17T21:29:51.382831Z"}},"outputs":[{"name":"stdout","text":"Multi-class Log Loss: 0.23617255159896322\n","output_type":"stream"}],"execution_count":3}]}